import sys
from typing import List, Optional
from dataclasses import dataclass

from sglang.srt.parser.conversation import chat_templates, generate_chat_conv


@dataclass
class ImageURL:
    url: str
    detail: str = "auto"


@dataclass
class ContentPart:
    type: str
    text: Optional[str] = None
    image_url: Optional[ImageURL] = None
    modalities: str = "image"


@dataclass
class Message:
    role: str
    content: any  # str or List[ContentPart]


@dataclass
class ChatCompletionRequest:
    model: str
    messages: List[Message]
    continue_final_message: bool = False


def test_qwen2_vl_prompt():
    """æµ‹è¯• Qwen2-VL çš„ prompt ç”Ÿæˆ"""
    
    print("=" * 80)
    print("æµ‹è¯• Qwen2.5-VL Chat Template Prompt ç”Ÿæˆ")
    print("=" * 80)
    
    # 1. ç¡®ä¿ qwen2-vl æ¨¡æ¿å·²æ³¨å†Œ
    if "qwen2-vl" not in chat_templates:
        raise RuntimeError("\nâš ï¸  qwen2-vl æ¨¡æ¿æœªæ³¨å†Œ")
    else:
        print("\nâœ… qwen2-vl æ¨¡æ¿å·²å­˜åœ¨")
    
    # 2. æ„é€ æµ‹è¯•è¯·æ±‚
    # from https://github.com/sgl-project/sglang/blob/main/docs/basic_usage/qwen3_vl.md
    request = ChatCompletionRequest(
        model="Qwen/Qwen2.5-VL-7B-Instruct",
        messages=[
            Message(
                role="user",
                content=[
                    ContentPart(type="text", text="æè¿°è¿™å¼ å›¾ç‰‡"),
                    ContentPart(
                        type="image_url",
                        image_url=ImageURL(url="https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true"),
                        modalities="image"
                    ),
                ],
            )
        ],
    )
    
    print("\n" + "=" * 80)
    print("è¾“å…¥è¯·æ±‚:")
    print("=" * 80)
    print(f"Model: {request.model}")
    print(f"Messages:")
    for msg in request.messages:
        print(f"  - Role: {msg.role}")
        if isinstance(msg.content, list):
            print(f"    Content:")
            for part in msg.content:
                if part.type == "text":
                    print(f"      - Text: {part.text}")
                elif part.type == "image_url":
                    print(f"      - Image URL: {part.image_url.url}")
    
    # 3. è°ƒç”¨ generate_chat_conv ç”Ÿæˆ Conversation å¯¹è±¡
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 1: è°ƒç”¨ generate_chat_conv()")
    print("=" * 80)
    
    template_name = "qwen2-vl"
    conv = generate_chat_conv(request, template_name)
    
    print(f"âœ… Conversation å¯¹è±¡åˆ›å»ºæˆåŠŸ")
    print(f"  - Template Name: {conv.name}")
    print(f"  - System Message: {conv.system_message}")
    print(f"  - Roles: {conv.roles}")
    print(f"  - Separator: {repr(conv.sep)}")
    print(f"  - Sep Style: {conv.sep_style}")
    print(f"  - Image Token: {conv.image_token}")
    print(f"  - Messages Count: {len(conv.messages)}")
    
    print(f"\n  Messages:")
    for i, (role, content) in enumerate(conv.messages):
        print(f"    [{i}] Role: {role}")
        print(f"        Content: {repr(content)}")
    
    if conv.image_data:
        print(f"\n  Image Data:")
        for i, img in enumerate(conv.image_data):
            print(f"    [{i}] {img}")
    
    # 4. è°ƒç”¨ get_prompt() ç”Ÿæˆæœ€ç»ˆ prompt
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 2: è°ƒç”¨ conv.get_prompt()")
    print("=" * 80)
    
    prompt = conv.get_prompt()
    
    print("âœ… Prompt ç”ŸæˆæˆåŠŸ\n")
    print("ç”Ÿæˆçš„ Prompt:")
    print("-" * 80)
    print(prompt)
    print("-" * 80)
    
    # 5. éªŒè¯ prompt æ ¼å¼
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 3: éªŒè¯ Prompt æ ¼å¼")
    print("=" * 80)
    
    expected_prompt = """<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
æè¿°è¿™å¼ å›¾ç‰‡<|vision_start|><|image_pad|><|vision_end|><|im_end|>
<|im_start|>assistant
"""
    
    print("\næœŸæœ›çš„ Prompt:")
    print("-" * 80)
    print(expected_prompt)
    print("-" * 80)
    
    # é€è¡Œæ¯”è¾ƒ
    print("\né€è¡Œæ¯”è¾ƒ:")
    print("-" * 80)
    
    prompt_lines = prompt.split('\n')
    expected_lines = expected_prompt.split('\n')
    
    max_lines = max(len(prompt_lines), len(expected_lines))
    all_match = True
    
    for i in range(max_lines):
        actual = prompt_lines[i] if i < len(prompt_lines) else "<ç¼ºå¤±>"
        expected = expected_lines[i] if i < len(expected_lines) else "<ç¼ºå¤±>"
        
        match = actual == expected
        all_match = all_match and match
        
        status = "âœ…" if match else "âŒ"
        print(f"è¡Œ {i+1:2d} {status}")
        print(f"  å®é™…: {repr(actual)}")
        print(f"  æœŸæœ›: {repr(expected)}")
        if not match:
            print(f"  å·®å¼‚: ä¸åŒ¹é…!")
        print()
    
    # 6. æœ€ç»ˆç»“æœ
    print("=" * 80)
    if all_match:
        print("ğŸ‰ æµ‹è¯•é€šè¿‡ï¼ç”Ÿæˆçš„ prompt ä¸æœŸæœ›æ ¼å¼å®Œå…¨ä¸€è‡´ï¼")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼ç”Ÿæˆçš„ prompt ä¸æœŸæœ›æ ¼å¼ä¸ä¸€è‡´ï¼")
    print("=" * 80)
    
    # 7. é¢å¤–æ£€æŸ¥å…³é”®å…ƒç´ 
    print("\n" + "=" * 80)
    print("é¢å¤–æ£€æŸ¥:")
    print("=" * 80)
    
    checks = [
        ("åŒ…å«ç³»ç»Ÿæ¶ˆæ¯å¼€å§‹æ ‡è®°", "<|im_start|>system" in prompt),
        ("åŒ…å«ç³»ç»Ÿæ¶ˆæ¯å†…å®¹", "You are a helpful assistant." in prompt),
        ("åŒ…å«ç”¨æˆ·æ¶ˆæ¯å¼€å§‹æ ‡è®°", "<|im_start|>user" in prompt),
        ("åŒ…å«æ–‡æœ¬å†…å®¹", "æè¿°è¿™å¼ å›¾ç‰‡" in prompt),
        ("åŒ…å«å›¾åƒ token", "<|vision_start|><|image_pad|><|vision_end|>" in prompt),
        ("åŒ…å«æ¶ˆæ¯ç»“æŸæ ‡è®°", "<|im_end|>" in prompt),
        ("åŒ…å«åŠ©æ‰‹æ¶ˆæ¯å¼€å§‹æ ‡è®°", "<|im_start|>assistant" in prompt),
        ("ä»¥åŠ©æ‰‹æ ‡è®°ç»“å°¾", prompt.strip().endswith("<|im_start|>assistant")),
    ]
    
    for check_name, result in checks:
        status = "âœ…" if result else "âŒ"
        print(f"{status} {check_name}")
    
    return all_match


def test_multimodal_variations():
    """æµ‹è¯•å¤šç§å¤šæ¨¡æ€åœºæ™¯"""
    
    print("\n\n" + "=" * 80)
    print("æµ‹è¯•å¤šç§åœºæ™¯")
    print("=" * 80)
    
    # åœºæ™¯ 1: çº¯æ–‡æœ¬
    print("\nåœºæ™¯ 1: çº¯æ–‡æœ¬æ¶ˆæ¯")
    print("-" * 80)
    request1 = ChatCompletionRequest(
        model="Qwen/Qwen2.5-VL-7B-Instruct",
        messages=[
            Message(role="user", content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
        ],
    )
    conv1 = generate_chat_conv(request1, "qwen2-vl")
    prompt1 = conv1.get_prompt()
    print(prompt1)
    
    # åœºæ™¯ 2: å¤šå¼ å›¾ç‰‡
    print("\nåœºæ™¯ 2: å¤šå¼ å›¾ç‰‡")
    print("-" * 80)
    request2 = ChatCompletionRequest(
        model="Qwen/Qwen2.5-VL-7B-Instruct",
        messages=[
            Message(
                role="user",
                content=[
                    ContentPart(type="text", text="æ¯”è¾ƒè¿™ä¸¤å¼ å›¾ç‰‡çš„åŒºåˆ«"),
                    ContentPart(
                        type="image_url",
                        image_url=ImageURL(url="https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true"),
                        modalities="image"
                    ),
                    ContentPart(
                        type="image_url",
                        image_url=ImageURL(url="https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true"),
                        modalities="image"
                    ),
                ],
            )
        ],
    )
    conv2 = generate_chat_conv(request2, "qwen2-vl")
    prompt2 = conv2.get_prompt()
    print(prompt2)
    
    # åœºæ™¯ 3: å›¾ç‰‡åœ¨æ–‡æœ¬å‰é¢
    print("\nåœºæ™¯ 3: å›¾ç‰‡åœ¨æ–‡æœ¬å‰é¢")
    print("-" * 80)
    request3 = ChatCompletionRequest(
        model="Qwen/Qwen2.5-VL-7B-Instruct",
        messages=[
            Message(
                role="user",
                content=[
                    ContentPart(
                        type="image_url",
                        image_url=ImageURL(url="https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true"),
                        modalities="image"
                    ),
                    ContentPart(type="text", text="è¿™æ˜¯ä»€ä¹ˆåŠ¨ç‰©ï¼Ÿ"),
                ],
            )
        ],
    )
    conv3 = generate_chat_conv(request3, "qwen2-vl")
    prompt3 = conv3.get_prompt()
    print(prompt3)
    
    # åœºæ™¯ 4: å¤šè½®å¯¹è¯
    print("\nåœºæ™¯ 4: å¤šè½®å¯¹è¯")
    print("-" * 80)
    request4 = ChatCompletionRequest(
        model="Qwen/Qwen2.5-VL-7B-Instruct",
        messages=[
            Message(
                role="user",
                content=[
                    ContentPart(type="text", text="æè¿°è¿™å¼ å›¾ç‰‡"),
                    ContentPart(
                        type="image_url",
                        image_url=ImageURL(url="https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true"),
                        modalities="image"
                    ),
                ],
            ),
            Message(role="assistant", content="è¿™æ˜¯ä¸€åªå¯çˆ±çš„å°ç‹—ã€‚"),
            Message(role="user", content="å®ƒæ˜¯ä»€ä¹ˆå“ç§ï¼Ÿ"),
        ],
    )
    conv4 = generate_chat_conv(request4, "qwen2-vl")
    prompt4 = conv4.get_prompt()
    print(prompt4)


if __name__ == "__main__":
    try:
        success = test_qwen2_vl_prompt()
        
        test_multimodal_variations()
        
        sys.exit(0 if success else 1)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
